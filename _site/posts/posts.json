[
  {
    "path": "posts/2021-03-17-cfb-data-api-access-and-manipulate-data-with-r-jsonlite-tidyverse/",
    "title": "College Football Data API with R",
    "description": "A fun introduction to accessing and manipulating data via the CollegeFootballData API with R, jsonlite, & tidyverse",
    "author": [
      {
        "name": "Jeff Asselin",
        "url": "https://jeffreyasselin.netlify.app/cfb_data_api_intro"
      }
    ],
    "date": "2021-03-17",
    "categories": [],
    "contents": "\r\nIntroduction\r\nI love sports. The action, the historical moments, the athletic feats, the camaraderie. I have enjoyed sports since I was a child and I will continue to enjoy sports for my whole life.\r\nI also love working with data. I enjoy accessing it, wrangling it, transforming it, finding quirks in it, and making cool visualizations of it.\r\nFor me, Sports Analytics is a marriage of these two loves.\r\nI have worked on various data analysis and data science projects in the past (NHL, NFL, NBA, PGA, etc.) which I hope to share on here one day, but I wanted to kick off my sports analytics writing journey with a new dataset. A fresh start.\r\nCollegeFootballData.com is an incredible resource for data discovery related to NCAA football. Kudos to the maintainer of this resource. They have an extensive API with great quick start guides and documentation.\r\nIn this article, I will show you, an R user (specifically RStudio), how to get started accessing data in R via this API and pull together a quick analysis and visualization.\r\nInstall Packages\r\nStart with installing and declaring the following packages:\r\n\r\n\r\nlibrary(httr)\r\nlibrary(jsonlite)\r\nlibrary(tidyverse)\r\nlibrary(ggplot2)\r\n\r\n\r\n\r\nConstruct an API request link\r\nIf you take a look at the CollegeFootballData API documentation page, you can find a list of all of the data accessible from this API and test out what a given request example will return.\r\nFor this intro article, I am going to pull “talent composite rankings” data, by team, for the last three years (2018 through 2020).\r\nNavigating the API documentation page, scroll down to the “Teams” subhead, under which you will see a GET button with “/talent” next to it. Click the “GET” button, then the “Try it out” button in the drop down. If you type in a year and hit “EXECUTE”, you will see what was executed. Under “Responses” there is a subhead “Request URL”. This is the URL we will want to use.\r\nSee below for storing your request URL as a variable:\r\n\r\n\r\ntest_url <- '[YOUR URL HERE]'\r\n\r\n\r\n\r\nMy URL looks like so:\r\n\r\n\r\ntest_url <- 'https://api.collegefootballdata.com/talent?year=2020'\r\n\r\n\r\n\r\nNext, we will test out our URL to see if we receive a good response from the API.\r\nTest your link\r\nNow that you have your URL, it’s time to send a request to the API. We can do this using the ‘fromJSON’ function from the jsonlite package, like so, and try to print the head of the response object:\r\n\r\n\r\ntest_response <- jsonlite::fromJSON(test_url)\r\n\r\nprint(head(test_response))\r\n\r\n\r\n  year     school talent\r\n1 2020    Georgia 990.47\r\n2 2020    Alabama 985.86\r\n3 2020 Ohio State 976.48\r\n4 2020    Clemson 915.57\r\n5 2020      Texas 892.91\r\n6 2020  Texas A&M 875.10\r\n\r\nGreat! Now that we know our URL is returning a data object that is in a format we can work with, let’s write a function that allows us to pull this data for multiple years.\r\nWrite a function\r\nFor this data request, we will write a function that will take one year as input and return a dataframe with the data for that year. We will then map this function to a list of years, which will return a list of dataframes, which we will then combine into one dataframe.\r\nSee function below:\r\n\r\n\r\n# Create function for pulling CFB team talent data, for all teams accessible from the API, \r\n#     by year, for a list of years\r\ncfbdata_talent_by_yr <- function(year_no) {\r\n  \r\n  # Construct URL\r\n  api_request <- paste0('https://api.collegefootballdata.com/talent?year=', as.character(year_no))\r\n\r\n  # Store API response\r\n  api_object <- jsonlite::fromJSON(api_request)\r\n  \r\n  # Check if the response is empty; if not, continue, if so, skip to next year in list\r\n  if (is.list(api_object) & length(api_object) == 0) { next }\r\n  if (is.null(api_object)) { next }\r\n  if (dim(api_object)[1] == 0) { next }\r\n  if (dim(api_object)[2] == 0) { next }\r\n  \r\n  # Store manipulated dataframe in df\r\n  talent_df <- api_object %>% \r\n    rename(team = school, talent_rating = talent) %>%\r\n    select(year, team, talent_rating) %>%\r\n    unique()\r\n  \r\n  return(talent_df)\r\n}\r\n\r\n\r\n\r\nWe are now ready to request data.\r\nRun your new data request\r\nYou can run your function like so below in order pull team talent composite rankings for the 2018, 2019, and 2020 seasons, storing the result in a new dataframe called “team_talent_df”:\r\n\r\n\r\n# Apply function to list of years with map\r\nteam_talent_df_list <- map(c(2018, 2019, 2020), cfbdata_talent_by_yr)\r\n\r\n# Use bind_rows to combine into one dataframe\r\nteam_talent_df <- bind_rows(team_talent_df_list, .id = 'column_label')\r\n\r\n# Get rid of new 'column_label' column, which we don't need\r\nteam_talent_df <- team_talent_df[,!(names(team_talent_df) == 'column_label')]\r\n\r\n# print head of df\r\nprint(head(team_talent_df))\r\n\r\n\r\n  year       team talent_rating\r\n1 2018 Ohio State        984.30\r\n2 2018    Alabama        978.54\r\n3 2018    Georgia        964.00\r\n4 2018        USC        933.65\r\n5 2018    Clemson        893.21\r\n6 2018        LSU        889.91\r\n\r\nLooks like our function worked and we have our data in a single dataframe! Let’s see if we can adjust the data at all to make it easier to work with before visualizing it.\r\nExplore and Manipulate Data\r\nNow that we have our dataset, let’s do some simple exploratory data analysis to check for any data quality issues. Below please find a handful of one-line function calls to check the data.\r\nThe function call ‘dim(df)’ tells us the dimensions of the dataframe; it looks like we have 686 rows and 4 columns.\r\n\r\n\r\n# print dim of df\r\nprint(dim(team_talent_df))\r\n\r\n\r\n[1] 686   3\r\n\r\nThe function call ‘summary(df)’ gives us a summary of each of the columns in the dataframe; it looks like even though ‘talent_rating’ is a number column, it is currently being stored as data type ‘character’:\r\n\r\n\r\n# print summary of df\r\nprint(summary(team_talent_df))\r\n\r\n\r\n      year          team           talent_rating     \r\n Min.   :2018   Length:686         Length:686        \r\n 1st Qu.:2018   Class :character   Class :character  \r\n Median :2019   Mode  :character   Mode  :character  \r\n Mean   :2019                                        \r\n 3rd Qu.:2020                                        \r\n Max.   :2020                                        \r\n\r\nLet’s adjust the data to set those to a numeric data type:\r\n\r\n\r\n# Change data type of \"talent_rating\" column from \"character\" to \"numeric\"\r\nteam_talent_df['talent_rating'] <- as.numeric(team_talent_df[['talent_rating']])\r\n\r\n\r\n\r\nAnd if we re-run the ‘summary’ function we get some new info:\r\n\r\n\r\n# print summary of df\r\nprint(summary(team_talent_df))\r\n\r\n\r\n      year          team           talent_rating   \r\n Min.   :2018   Length:686         Min.   :  3.30  \r\n 1st Qu.:2018   Class :character   1st Qu.: 46.85  \r\n Median :2019   Mode  :character   Median :344.01  \r\n Mean   :2019                      Mean   :335.59  \r\n 3rd Qu.:2020                      3rd Qu.:580.48  \r\n Max.   :2020                      Max.   :990.47  \r\n\r\nWell done! Now that we have formatted the data to our liking and reviewed some summary statistics, let’s create a visualization.\r\nVisualize\r\nOne thing I am interested in seeing is how “Talent Rating” has trended, over the three years that we pulled, for a select group of the top teams.\r\nLet’s visualize it:\r\n\r\n\r\n# Bar Chart displaying talent_rating for the teams Alabama, Ohio State, Clemson, Oklahoma, and LSU for the years 2018 through 2020\r\nteam_talent_rankings_viz <- team_talent_df %>%\r\n                              filter(team %in% c('Alabama','Ohio State','Clemson', 'Oklahoma', 'LSU')) %>%\r\n                              ggplot(aes(x = fct_reorder(team, talent_rating, .desc = TRUE), y = talent_rating, \r\n                                          group = factor(year), fill = factor(year))) + \r\n                              geom_bar(stat='identity',position='dodge') +\r\n                            labs(x = 'Team',\r\n                                 y = 'Composite Talent Rating',\r\n                                 title = 'Composite Talent Rating - 2018 through 2020',\r\n                                 subtitle = 'Alabama, Ohio State, Clemson, Oklahoma, LSU Only',\r\n                                 legend = 'Year') + \r\n                            guides(fill=guide_legend(title='Year')) + \r\n                             theme_classic()\r\n\r\nprint(team_talent_rankings_viz)\r\n\r\n\r\n\r\n\r\nLastly, let’s write up some observations.\r\nConclusion\r\nIn this article I showed you how to test pulling data directly from an open-source API, write a function to do so more efficiently, explore, manipulate, and adjust data to fit your needs, and develop a clear and concise data visualization from that data.\r\nThe “Composite Talent Ratings” for the top teams should come as little surprise: Alabama is far and away the most talented team year in and year out, and we can see that this was the case for the three years we pulled. Ohio State is also a storied program and has had the talent to match up with Alabama the last three years, while Clemson, LSU, and Oklahoma, although certainly highly talented, see more variability year-to-year when it comes to their “Talent Ratings”.\r\nThere is plenty more you could do with this data, from correlating talent ratings with end-of-season outcomes or week-to-week win probabilities, to understanding how individual players contribute to this rating and if injuries could have major mid-season impacts, as well as many other potential data discoveries.\r\nMy hope is for you to use this introduction to dig into the data and explore further; please tweet me @JeffreyAsselin9 with your analyses or any questions, I would love to help out and cheer you on!\r\nThanks again to the maintainers of CollegeFootballData.com and RStudio. Happy Coding!\r\nDistill is a publication format for scientific and technical writing, native to the web.\r\nLearn more about using Distill at https://rstudio.github.io/distill.\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-03-17-cfb-data-api-access-and-manipulate-data-with-r-jsonlite-tidyverse/cfb-data-api-access-and-manipulate-data-with-r-jsonlite-tidyverse_files/figure-html5/unnamed-chunk-11-1.png",
    "last_modified": "2021-03-28T16:17:12-04:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-02-02-jeffs-journal-declaration-of-existence/",
    "title": "Jeff's Journal - Declaration of Existence",
    "description": "Existence Proclamation.",
    "author": [
      {
        "name": "Jeff Asselin",
        "url": "https://jeffreyasselin.netlify.app/declaration_of_existence"
      }
    ],
    "date": "2021-02-02",
    "categories": [],
    "contents": "\r\nHi, my name is Jeff Asselin. I currently work as a data analyst at a company called TechTarget, based out of Newton, Massachusetts.\r\nI wanted to start a blog mostly because I am tired of (read: inspired by) reading a ton of awesome content on other data blogs; I want to showcase what I have learned (both academically and by messier means), particularly in areas beyond my core competencies, and collaborate with other data practitioners wherever and whenever possible (reach out to me on Twitter if you are looking to collab!). Lastly, my hope is that by sharing my work I can help or inspire others following a similar journey.\r\nAs a means of putting my goals and aspirations out into the world, I am planning to write about some sports analytics R projects, scripts, processes, and models I have developed. I am also hoping to write about data explorations in the areas of music, books, and pop culture, and possibly share things like book, movie, and TV reviews if I feel inspired.\r\nLastly, this blog was created and will be maintained using RStudio and the distill R package, thank you to RStudio, the maintainers of distill, and the open-source community.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2021-02-15T12:54:23-05:00",
    "input_file": {}
  },
  {
    "path": "posts/welcome/",
    "title": "Welcome to Jeff's Journal",
    "description": "Welcome to my new blog, Jeff's Journal. I hope you enjoy \nreading what I have to say!",
    "author": [
      {
        "name": "Jeff Asselin",
        "url": "https://jeffreyasselin.netlify.app/welcome_post"
      }
    ],
    "date": "2021-01-18",
    "categories": [],
    "contents": "\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2021-02-15T12:54:09-05:00",
    "input_file": {}
  }
]
